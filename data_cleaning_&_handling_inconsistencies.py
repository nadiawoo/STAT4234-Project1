# -*- coding: utf-8 -*-
"""Data Cleaning & Handling Inconsistencies

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r0IacUfZWRN2OYFn_L8kGhpCZv-9uLhv
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import ast

spotify_df = pd.read_csv("/content/drive/My Drive/Project 1/tracks_features.csv")
grammy = pd.read_csv("/content/drive/MyDrive/Project 1/grammy_winners_cleaned.csv")

"""**Getting a sense of what the spotify_df looks like**"""

spotify_df.head()

print(spotify_df.dtypes)

##ensuring the datatypes are appropriate
spotify_df[['mode', 'explicit']] = spotify_df[['mode', 'explicit']].astype(bool)

##converting the release date into time objects & cleaning the date-related columns

# Convert 'release_date' to datetime
def convert_release_date(date):
    if "-" in str(date):  # If it's already in YYYY-MM-DD format
        return pd.to_datetime(date, format="%Y-%m-%d", errors="coerce")
    else:  # If it's only a year, assume January 1st
        return pd.to_datetime(str(date) + "-01-01", format="%Y-%m-%d", errors="coerce")

spotify_df["release_date_parsed"] = spotify_df["release_date"].apply(convert_release_date)

#removing the year, as there is many inconsistencies and is not necessary provided we already have data with release date

#spotify_df = spotify_df.drop(columns=["year"])

spotify_df.isna().sum() #there are 1052 NA for parsed release date but not for actual release date

spotify_df[spotify_df['release_date_parsed'].isna() ==1] #shows us that the unparsed ones are dates with only yyyy-mm

# Select only rows where 'release_date_parsed' is NaT (not parsed)
mask = spotify_df['release_date_parsed'].isna()

# Convert yyyy-mm format to yyyy-mm-01, assuming that the release data is the first day of the month
spotify_df.loc[mask, 'release_date_parsed'] = pd.to_datetime(
    spotify_df.loc[mask, 'release_date'].astype(str) + "-01",
    format="%Y-%m-%d",
    errors="coerce"
)

spotify_df.isna().sum() #the NAs left are ones where release date is not available from the beginning

#making sure that the album and the songs are named properly
spotify_df[spotify_df['album'].isna() ==1] #these albums are all names None, so they will be renamed

# Convert "None" (string) to actual NaN
spotify_df["album"] = spotify_df["name"].replace("NaN", "None")

spotify_df[spotify_df['name'].isna() ==1] #these may be songs that have names similar to NA; manual labelling is required to retrieve these names - these are later found to be all named None

# Assign names manually
spotify_df.loc[spotify_df['id'] == "7r3l7R0Ob1XcRk6woND7It", "name"] = "None"
spotify_df.loc[spotify_df['id'] == "0Ii9PaRffU4y8Tg1qMfV92", "name"] = "None"
spotify_df.loc[spotify_df['id'] == "5dQ6x9vR5gaxIQFAqFTGhN", "name"] = "None"
spotify_df.loc[spotify_df['id'] == "5dQ6x9vR5gaxIQFAqFTGhN", "album"] = "None"

#converting the song duration from ms to minutes
spotify_df['duration_min'] = spotify_df['duration_ms'] / 60000

#save progress
spotify_df.to_csv("spotify_df_adjusted.csv", index=False)

"""**Below, I am focusing on adding details to each of the artist of each song.For each song, the artist names will be parsed, then for each artist of the song, their nomination and awards will be included. Considering the size of the database and the high fragmentation, I will split it into two different datasets**"""

coartists_df = spotify_df[['id', 'album', 'name', 'artists', 'artist_ids']].copy()

# Function to safely convert string lists to actual lists
def safe_list_conversion(value):
    if isinstance(value, list):  # Already a list
        return value
    if isinstance(value, str) and value.startswith("["):  # Likely a string list
        try:
            return ast.literal_eval(value)  # Convert safely
        except (ValueError, SyntaxError):  # Catch invalid cases
            return []
    return []  # If it's not a valid list, return empty list

# Apply safe conversion to both 'artists' and 'artist_ids'
coartists_df["artists"] = coartists_df["artists"].apply(safe_list_conversion)
coartists_df["artist_ids"] = coartists_df["artist_ids"].apply(safe_list_conversion)

# Define max number of artists to extract
max_artists = 51

# Create a temporary dictionary to hold expanded values
expanded_data = {"id": coartists_df["id"]}  # Retain ID column

for i in range(max_artists):
    expanded_data[f"artist_{i+1}"] = []
    expanded_data[f"artist_id_{i+1}"] = []

# Populate dictionary in a vectorized way
for artist_list, artist_id_list in zip(coartists_df["artists"], coartists_df["artist_ids"]):
    for i in range(max_artists):
        expanded_data[f"artist_{i+1}"].append(artist_list[i] if len(artist_list) > i else None)
        expanded_data[f"artist_id_{i+1}"].append(artist_id_list[i] if len(artist_id_list) > i else None)

# Convert dictionary to DataFrame
expanded_df = pd.DataFrame(expanded_data)

# Concatenate with the original DataFrame efficiently
coartists_df = pd.concat([coartists_df.reset_index(drop=True), expanded_df], axis=1)

spotify_df.head()

# Ensure the ID column is retained
coartists_df = spotify_df[['id', 'album', 'name', 'artists', 'artist_ids']].copy()

# Function to safely convert string lists to actual lists
def safe_list_conversion(value):
    if isinstance(value, list):  # Already a list
        return value
    if isinstance(value, str) and value.startswith("["):  # Likely a string list
        try:
            return ast.literal_eval(value)  # Convert safely
        except (ValueError, SyntaxError):  # Catch invalid cases
            return []
    return []  # If it's not a valid list, return empty list

# Apply safe conversion to both 'artists' and 'artist_ids'
coartists_df["artists"] = coartists_df["artists"].apply(safe_list_conversion)
coartists_df["artist_ids"] = coartists_df["artist_ids"].apply(safe_list_conversion)

# Define max number of artists to extract
max_artists = 51

# Create a temporary dictionary to hold expanded values
expanded_data = {"id": coartists_df["id"]}  # Retain ID column

for i in range(max_artists):
    expanded_data[f"artist_{i+1}"] = []
    expanded_data[f"artist_id_{i+1}"] = []

# Populate dictionary in a vectorized way
for artist_list, artist_id_list in zip(coartists_df["artists"], coartists_df["artist_ids"]):
    for i in range(max_artists):
        expanded_data[f"artist_{i+1}"].append(artist_list[i] if len(artist_list) > i else None)
        expanded_data[f"artist_id_{i+1}"].append(artist_id_list[i] if len(artist_id_list) > i else None)

# Convert dictionary to DataFrame
coartists_df = pd.concat([coartists_df.reset_index(drop=True), expanded_df], axis=1)

# Combining the coartist_df with Grammy awards and nominations
for i in range(1, max_artists + 1):  # Loop through artist_1 to artist_51
    artist_col = f"artist_{i}"
    grammy_col_awards = f"grammy_awards_{i}"
    grammy_col_nominations = f"grammy_nominations_{i}"

    # Merge Grammy data for each artist individually
    coartists_df = coartists_df.merge(
        grammy,
        left_on=artist_col,
        right_on="Artist",
        how="left"
    ).drop(columns=["Artist"])  # Drop redundant column after merge

    # Rename merged Grammy columns to reflect artist numbers
    coartists_df.rename(
        columns={
            "Grammy Awards": grammy_col_awards,
            "Grammy Nominations": grammy_col_nominations
        },
        inplace=True
    )

# Fill NaN Grammy awards/nominations with 0 (optional)
for i in range(1, max_artists + 1):
    coartists_df[f"grammy_awards_{i}"] = coartists_df[f"grammy_awards_{i}"].fillna(0)
    coartists_df[f"grammy_nominations_{i}"] = coartists_df[f"grammy_nominations_{i}"].fillna(0)

# Reorder columns
ordered_columns = ["id"]  # ID first

for i in range(1, max_artists + 1):
    ordered_columns.append(f"artist_{i}")  # Artist Name
    ordered_columns.append(f"artist_id_{i}")  # Artist ID
    ordered_columns.append(f"grammy_awards_{i}")  # Grammy Awards
    ordered_columns.append(f"grammy_nominations_{i}")  # Grammy Nominations

coartists_df = coartists_df[ordered_columns]

#Summing award and nomination number per song

# Ensure Grammy-related columns exist in the DataFrame
grammy_awards_cols = [col for col in coartists_df.columns if "grammy_awards_" in col]
grammy_nominations_cols = [col for col in coartists_df.columns if "grammy_nominations_" in col]

# Efficiently sum across Grammy columns
coartists_df["total_grammy_awards"] = coartists_df[grammy_awards_cols].sum(axis=1, numeric_only=True)
coartists_df["total_grammy_nominations"] = coartists_df[grammy_nominations_cols].sum(axis=1, numeric_only=True)

# Efficiently create the final DataFrame for merging

awards_nominations_per_song = pd.DataFrame

awards_nominations_per_song = coartists_df[['id', 'total_grammy_awards', 'total_grammy_nominations']].copy()

#save progress again
awards_nominations_per_song.to_csv("awards_nominations_per_song.csv", index=False)

"""Understanding that our main focus is to look at any variables that contribute to the popularity of a song; from the coartists_df we will be merging the number of awards and nominations won by the artists of each song with the spotify_df"""

# Remove duplicate columns if they exist
awards_nominations_per_song = awards_nominations_per_song.loc[:, ~awards_nominations_per_song.columns.duplicated()]

# Perform the merge safely
spotify_df_merged = spotify_df.merge(
    awards_nominations_per_song,
    on="id",
    how="left"
)

spotify_df_merged.columns

"""**Dataframe for the further steps**"""

#final df for EDA and further analysis
spotify_df_merged.to_csv("spotify_df_merged.csv", index = False)

spotify_df_merged.head()